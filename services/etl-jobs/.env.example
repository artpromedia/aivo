# ETL Jobs Service Configuration
# Copy this file to .env and configure as needed

# Service Configuration
SERVICE_NAME=etl-jobs
VERSION=0.1.0
DEBUG=false
LOG_LEVEL=INFO

# Kafka/Redpanda Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_EVENTS_RAW=events_raw
KAFKA_CONSUMER_GROUP=etl-snowflake
KAFKA_AUTO_OFFSET_RESET=earliest

# AWS S3 Configuration
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-west-2
S3_BUCKET_RAW_EVENTS=aivo-data-raw
S3_PREFIX_EVENTS=events/

# Parquet Configuration
PARQUET_COMPRESSION=snappy
PARQUET_ROW_GROUP_SIZE=100000
BATCH_SIZE=10000
FLUSH_INTERVAL_SECONDS=300

# Snowflake Configuration
SNOWFLAKE_ACCOUNT=
SNOWFLAKE_USERNAME=
SNOWFLAKE_PASSWORD=
SNOWFLAKE_DATABASE=AIVO_ANALYTICS
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_SCHEMA_RAW=RAW
SNOWFLAKE_SCHEMA_ANALYTICS=ANALYTICS

# Data Retention
RAW_DATA_RETENTION_MONTHS=18
AGGREGATE_DATA_RETENTION_YEARS=7

# Processing Configuration
WORKER_COUNT=4
MAX_MEMORY_MB=2048
